<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Enhanced Question-Answering Chatbot</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/qna"></script>
  <style>
    #progress-container {
      width: 100%;
      height: 20px;
      background-color: #ddd;
    }
    #progress-bar {
      width: 0;
      height: 100%;
      background-color: #4caf50;
      text-align: center;
      transition: width 0.5s;
    }
    #chat-container {
      max-height: 400px;
      overflow-y: auto;
      padding: 10px;
      border: 1px solid #ccc;
      background-color: #f9f9f9;
    }
    .chat-bubble {
      padding: 10px;
      border-radius: 10px;
      margin: 5px 0;
      word-wrap: break-word;
    }
    .chat-bubble.you {
      background-color: #e1f5fe;
      text-align: left;
    }
    .chat-bubble.chatbot {
      background-color: #c8e6c9;
      text-align: right;
    }
    .chat-bubble.system {
      background-color: #fff3e0;
      text-align: center;
      font-style: italic;
    }
    .chat-controls {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 10px;
      border-top: 1px solid #ccc;
      background-color: #f1f1f1;
    }
  </style>
</head>
<body>
  <h1>Enhanced Question-Answering Chatbot</h1>
  
  <textarea id="system-prompt" rows="3" placeholder="Enter system prompt here..." aria-label="System prompt"></textarea>
  
  <div id="progress-container">
    <div id="progress-bar">Loading Model (0%)</div>
  </div>
  
  <div id="chat-container"></div>

  <div class="chat-controls">
    <input type="text" id="user-input" placeholder="Ask a question..." aria-label="Question input">
    <button id="ask-button">Ask</button>
    <button id="reset-chat">Reset</button>
    <button id="load-model">Load Model</button>
    <select id="model-select">
      <option value="bert">BERT</option>
      <option value="roberta">RoBERTa</option>
      <option value="albert">ALBERT</option>
      <option value="gpt3">GPT-3.5</option>
    </select>
  </div>

  <script>
    const chatContainer = document.getElementById("chat-container");
    const userInput = document.getElementById("user-input");
    const progressBar = document.getElementById("progress-bar");
    const askButton = document.getElementById("ask-button");
    const resetChatButton = document.getElementById("reset-chat");
    const loadModelButton = document.getElementById("load-model");
    const modelSelect = document.getElementById("model-select");
    const systemPrompt = document.getElementById("system-prompt");

    let bertModel = null;
    let currentModel = 'bert';
    let modelLoaded = false;
    let messageQueue = [];
    let chatHistory = [];

    function appendChatBubble(text, role) {
      const bubble = document.createElement("div");
      bubble.className = `chat-bubble ${role}`;
      bubble.textContent = text;
      chatContainer.appendChild(bubble);
      chatHistory.push({ text, role });
      chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    function updateProgressBar(progress) {
      progressBar.style.width = `${progress}%`;
      progressBar.textContent = `Loading Model (${progress}%)`;
    }

    function disableControls(disable) {
      userInput.disabled = disable;
      askButton.disabled = disable;
      modelSelect.disabled = disable;
    }

    async function loadModel() {
      if (modelLoaded) {
        appendChatBubble("Chatbot: Model already loaded.", 'chatbot');
        return;
      }

      disableControls(true);
      simulateLoadingProgress(3000, async () => {
        try {
          if (currentModel === 'bert') {
            if (bertModel) {
              appendChatBubble("Chatbot: Using cached BERT model.", 'chatbot');
            } else {
              bertModel = await qna.load();
            }
            modelLoaded = true;
            appendChatBubble("Chatbot: BERT model loaded successfully.", 'chatbot');
          } else {
            appendChatBubble("Chatbot: Unsupported model.", 'chatbot');
          }
        } catch (error) {
          appendChatBubble("Chatbot: Model loading failed.", 'chatbot');
          console.error("Error loading model:", error);
        } finally {
          disableControls(false);
        }
      });
    }

    async function simulateLoadingProgress(duration, callback) {
      const steps = 10;
      const stepTime = duration / steps;
      let progress = 0;
      const interval = setInterval(() => {
        progress += 10;
        updateProgressBar(progress);
        if (progress >= 100) {
          clearInterval(interval);
          callback();
        }
      }, stepTime);
    }

    async function askQuestion() {
      if (!modelLoaded) {
        appendChatBubble("Chatbot: The model is not yet loaded. Please wait.", 'chatbot');
        return;
      }

      const question = userInput.value.trim();
      if (question === "") return;

      const systemText = systemPrompt.value.trim();
      const context = systemText || "Default context for question-answering.";

      appendChatBubble("You: " + question, 'you');

      try {
        if (messageQueue.length > 0) {
          appendChatBubble("Chatbot: Processing request...", 'chatbot');
          await Promise.all(messageQueue);
          messageQueue = [];
        }

        const answer = await getAnswer(question);
        appendChatBubble("Chatbot: " + answer, 'chatbot');
      } catch (error) {
        appendChatBubble("Chatbot: Error answering the question.", 'chatbot');
        console.error("Error getting answer:", error);
      }

      userInput.value = ""; // Clear the input field
    }

    async function getAnswer(question) {
      if (!bertModel) {
        await loadModel(); // Ensure model is loaded
      }

      const contextOptions = {
        default: "Sample context to demonstrate BERT's question-answering capability.",
        system: "System context with specific information.",
        user: "Context provided by the user."
      };

      const systemText = systemPrompt.value.trim();
      const context = contextOptions.default;
      const answers = await bertModel.findAnswers(question, context);

      return answers.length > 0 ? answers[0].text : "I need more information.";
    }

    askButton.addEventListener("click", askQuestion);
    loadModelButton.addEventListener("click", loadModel);
    resetChatButton.addEventListener("click", () => {
      chatContainer.innerHTML = ""; // Clear chat history
      appendChatBubble("System: Chat reset.", 'system'); // Reset system message
      loadModel(); // Reload the model
    });

    modelSelect.addEventListener("change", (e) => {
      currentModel = e.target.value;
      modelLoaded = false; // Reset model status
      appendChatBubble(`Chatbot: Switched to ${currentModel}.`, 'chatbot');
    });

    loadModel(); // Load model on startup
  </script>
</body>
</html>
